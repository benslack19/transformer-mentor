{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650940f2",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks and LSTMs/GRUs\n",
    "\n",
    "Following [Classifying Names with a Character-Level RNN](https://docs.pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f59db",
   "metadata": {},
   "source": [
    "For each character, generate a prediction and hidden state at each step by feeding its *previous* hidden state in each next step. Take the final prediction to be the output, which class the word belongs to.\n",
    "\n",
    "The task is to train on thousands of last names from 18 different languages and predict which language a name is based on the spelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "099db6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05ee689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f06c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "torch.set_default_device(device)\n",
    "print(f\"Using device = {torch.get_default_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45259e7c",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954fd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use \"_\" to represent an out-of-vocabulary character, that is, any character we are not handling in our model\n",
    "allowed_characters = string.ascii_letters + \" .,;'\" + \"_\"\n",
    "n_letters = len(allowed_characters)\n",
    "\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\" and c in allowed_characters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925d961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56059223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting 'Ślusàrski' to Slusarski\n"
     ]
    }
   ],
   "source": [
    "# example of name to convert\n",
    "print(f\"converting 'Ślusàrski' to {unicodeToAscii('Ślusàrski')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b078cc",
   "metadata": {},
   "source": [
    "# Turn names into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f4e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    # return our out-of-vocabulary character if we encounter a letter unknown to our model\n",
    "    if letter not in allowed_characters:\n",
    "        return allowed_characters.find(\"_\")\n",
    "    else:\n",
    "        return allowed_characters.find(letter)\n",
    "\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2c25cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The letter 'a' becomes\n",
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The letter 'a' becomes\\n{lineToTensor('a')}\")  # notice that the first position in the tensor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2599347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name 'Ahn' becomes\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The name 'Ahn' becomes\\n{lineToTensor('Ahn')}\")  # notice 'A' sets the 27th index to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d02d7aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name 'Abba' becomes\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The name 'Abba' becomes\\n{lineToTensor('Abba')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172f180",
   "metadata": {},
   "source": [
    "# Use `Dataset`` and `DataLoader` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b9bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38060d36",
   "metadata": {},
   "source": [
    "Note: \"Provenance of the dataset\" means keeping track of who, what, when, where, and how of the data. It's critical metadata that can be helpful for reproducibility purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dfa39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir  # for provenance of the dataset\n",
    "        self.load_time = time.localtime  # for provenance of the dataset\n",
    "        labels_set = set()  # set of all classes\n",
    "\n",
    "        self.data = []\n",
    "        self.data_tensors = []\n",
    "        self.labels = []\n",
    "        self.labels_tensors = []\n",
    "\n",
    "        # read all the ``.txt`` files in the specified directory\n",
    "        text_files = glob.glob(os.path.join(data_dir, \"*.txt\"))\n",
    "        for filename in text_files:\n",
    "            label = os.path.splitext(os.path.basename(filename))[0]\n",
    "            labels_set.add(label)\n",
    "            lines = open(filename, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "            for name in lines:\n",
    "                self.data.append(name)\n",
    "                self.data_tensors.append(lineToTensor(name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "        # Cache the tensor representation of the labels\n",
    "        # BL added `sorted` here to maintain alphabetical order of languages\n",
    "        self.labels_uniq = sorted(list(labels_set))\n",
    "        for idx in range(len(self.labels)):\n",
    "            temp_tensor = torch.tensor([self.labels_uniq.index(self.labels[idx])], dtype=torch.long)\n",
    "            self.labels_tensors.append(temp_tensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_item = self.data[idx]\n",
    "        data_label = self.labels[idx]\n",
    "        data_tensor = self.data_tensors[idx]\n",
    "        label_tensor = self.labels_tensors[idx]\n",
    "\n",
    "        return label_tensor, data_tensor, data_label, data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a7d3d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 20074 items of data\n"
     ]
    }
   ],
   "source": [
    "alldata = NamesDataset(\"../local_data/names\")\n",
    "print(f\"loaded {len(alldata)} items of data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "392a2263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../local_data/names'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provenance of the dataset\n",
    "alldata.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d94949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2025, tm_mon=7, tm_mday=25, tm_hour=5, tm_min=2, tm_sec=25, tm_wday=4, tm_yday=206, tm_isdst=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.load_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21eb6e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example = (tensor([2]), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]]), 'Czech', 'Abl')\n"
     ]
    }
   ],
   "source": [
    "# first dataset example\n",
    "# tuple of\n",
    "# label_tensor: tensor representation of the label (single integer value)\n",
    "# data_tensor: output of name being converted using lineToTensor\n",
    "# data_label: class (the language)\n",
    "# data_item: the name being classified\n",
    "print(f\"example = {alldata[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b2e37",
   "metadata": {},
   "source": [
    "Use `torch.utils.data` to create a train/test split as a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cc152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train examples = 17063, validation examples = 3011\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    alldata, [0.85, 0.15], generator=torch.Generator(device=device).manual_seed(2024)\n",
    ")\n",
    "\n",
    "print(f\"train examples = {len(train_set)}, validation examples = {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, line_tensor):\n",
    "        rnn_out, hidden = self.rnn(line_tensor)\n",
    "        output = self.h2o(hidden[0])\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "932e0ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (rnn): RNN(58, 128)\n",
      "  (h2o): Linear(in_features=128, out_features=18, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "rnn = CharRNN(n_letters, n_hidden, len(alldata.labels_uniq))\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9539, -2.8097, -2.7657, -2.8274, -2.8341, -2.9097, -2.9939, -3.0721,\n",
      "         -2.7528, -2.8996, -2.8607, -2.9514, -3.0111, -2.9556, -2.8843, -2.7442,\n",
      "         -2.9206, -2.9529]], grad_fn=<LogSoftmaxBackward0>)\n",
      "('Scottish', 15)\n"
     ]
    }
   ],
   "source": [
    "def label_from_output(output, output_labels):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    label_i = top_i[0].item()\n",
    "    return output_labels[label_i], label_i\n",
    "\n",
    "\n",
    "input = lineToTensor(\"Albert\")\n",
    "output = rnn(input)  # this is equivalent to ``output = rnn.forward(input)``\n",
    "print(output)\n",
    "print(label_from_output(output, alldata.labels_uniq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f9d7d",
   "metadata": {},
   "source": [
    "# Theoretical understanding and implementation with numpy\n",
    "\n",
    "The description of RNN's from [Kartpathy's blog](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) seems intuitive:\n",
    "\n",
    "> [The] output vector’s contents are influenced not only by the input you just fed in, but also on the entire history of inputs you’ve fed in in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda6cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15314bb4",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Initializes the SimpleRNN model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): The number of expected features in the input `x`.\n",
    "                              For word embeddings, this would be the embedding dimension.\n",
    "            hidden_size (int): The number of features in the hidden state `h`.\n",
    "            output_size (int): The size of the output layer (e.g., number of classes for classification).\n",
    "            num_layers (int, optional): Number of recurrent layers. Defaults to 1.\n",
    "        \"\"\"\n",
    "        super(SimpleRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the RNN layer\n",
    "        # batch_first=True means input/output tensors are (batch, seq, feature)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Define a linear layer to map the RNN's output to the desired output_size\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the RNN model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, sequence_length, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        # Initialize hidden state with zeros\n",
    "        # The hidden state tensor has shape (num_layers * num_directions, batch_size, hidden_size)\n",
    "        # For a simple RNN, num_directions is 1.\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Pass input through the RNN layer\n",
    "        # output: (batch_size, sequence_length, hidden_size * num_directions)\n",
    "        # hn: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        output, hn = self.rnn(x, h0)\n",
    "\n",
    "        # We are interested in the output of the last time step for classification/prediction.\n",
    "        # In batch_first=True mode, output[:, -1, :] gives the last time step's output for all batches.\n",
    "        # This is equivalent to hn[-1, :, :] if num_layers = 1 and it's a simple RNN.\n",
    "        # For multi-layered RNNs, hn[-1] is the final hidden state of the last layer.\n",
    "        final_output = self.fc(output[:, -1, :]) # Taking the output of the last time step\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970e10ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-08-06T23:14:29.951880+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.11\n",
      "IPython version      : 9.4.0\n",
      "\n",
      "Compiler    : GCC 12.2.0\n",
      "OS          : Linux\n",
      "Release     : 6.10.14-linuxkit\n",
      "Machine     : aarch64\n",
      "Processor   : \n",
      "CPU cores   : 7\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa3c2d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8823a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
